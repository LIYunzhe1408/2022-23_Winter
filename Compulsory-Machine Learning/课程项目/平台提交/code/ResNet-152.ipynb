{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBDhXnwYMu28"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuNe7FQEM6LZ"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-wa0IHRNdZS"
   },
   "outputs": [],
   "source": [
    "!ls ./drive/MyDrive/data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gQnUn7d83NM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "#pip install torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "#https://pytorch.org/docs/stable/torchvision/index.html\n",
    "import imageio\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JiO9T6xP8651"
   },
   "outputs": [],
   "source": [
    "data_dir = './drive/MyDrive/data_3'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "CLASS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvgnG7Js9F-9"
   },
   "outputs": [],
   "source": [
    "cat_to_name = {'1': 'BACTERIA', '2': 'NORMAL', '3': 'VIRUS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvjI3X4J9KaR"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyKNPmd59Lt1"
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, CLASS),\n",
    "                                   nn.LogSoftmax(dim=1))\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeEZAqNr9NKx"
   },
   "outputs": [],
   "source": [
    "model_name = 'resnet'  #['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception']\n",
    "feature_extract = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dhgvaec79PIw"
   },
   "outputs": [],
   "source": [
    "def im_convert(tensor):\n",
    "    \"\"\" 展示数据\"\"\"\n",
    "    \n",
    "    image = tensor.to(\"cpu\").clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    image = image.clip(0, 1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nFAoxQT9RTq"
   },
   "outputs": [],
   "source": [
    "# 是否用GPU训练\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCsMqg0_9S0p"
   },
   "outputs": [],
   "source": [
    "model_ft, input_size = initialize_model(model_name, CLASS, feature_extract, use_pretrained=True)\n",
    "\n",
    "# GPU模式\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# 保存文件的名字\n",
    "filename='./drive/MyDrive/data_3/checkpoint.pth'\n",
    "\n",
    "# 加载模型\n",
    "checkpoint = torch.load(filename)\n",
    "best_acc = checkpoint['best_acc']\n",
    "model_ft.load_state_dict(checkpoint['state_dict'])\n",
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-x5ktW1z9mkS"
   },
   "outputs": [],
   "source": [
    "data_transform1 = {\n",
    "\n",
    "     \"singlepic\":transforms.Compose([transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "   \n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTIBxRJN9oyN"
   },
   "outputs": [],
   "source": [
    "batch_size1 = 624\n",
    "image_datasets1 = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transform1[x]) for x in ['singlepic']}\n",
    "dataloaders1 = {x: torch.utils.data.DataLoader(image_datasets1[x], batch_size=batch_size1, shuffle=False) for x in ['singlepic']}\n",
    "dataset_sizes1 = {x: len(image_datasets1[x]) for x in ['singlepic']}\n",
    "class_names1 = image_datasets1['singlepic'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KM3YwPFw9q1y"
   },
   "outputs": [],
   "source": [
    "# 得到一个batch的测试数据\n",
    "dataiter1 = iter(dataloaders1[\"singlepic\"])\n",
    "images, labels = next(dataiter1)\n",
    "\n",
    "model_ft.eval()\n",
    "\n",
    "if train_on_gpu:\n",
    "    output = model_ft(images.cuda())\n",
    "else:\n",
    "    output = model_ft(images)\n",
    "# labels+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DM8tXiaxZZsP"
   },
   "outputs": [],
   "source": [
    "labels+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdPGGRhT9xK4"
   },
   "outputs": [],
   "source": [
    "_, preds_tensor = torch.max(output, 1)\n",
    "\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "preds+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cUZrzE39y2O"
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20, 20))\n",
    "columns =3\n",
    "rows = 4\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    ax = fig.add_subplot(rows, columns, i+1, xticks=[], yticks=[])\n",
    "    plt.imshow(im_convert(images[i]))\n",
    "    ax.set_title(\"{}\".format(cat_to_name[str((preds+1)[i])]),\n",
    "                color=(\"green\"))\n",
    "    print(cat_to_name[str((preds+1)[i])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-x3eND-9zyg"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "false = 0\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] == labels[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        false += 1\n",
    "print(correct / (correct+false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dlGA1f5E6G1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(labels+1, preds+1)\n",
    "cm = pd.DataFrame(cm , index = ['1','2','3'] , columns = ['1','2','3'])\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = ['Bacteria','Normal','Virus'],yticklabels = ['Bacteria','Normal', 'Virus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvmJTCQOFGwm"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "fpr, tpr, thersholds = roc_curve(preds+1, np.array(labels+1), pos_label=3)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, '-', label='ROC (area = {0:.2f})'.format(roc_auc), lw=2)\n",
    " \n",
    "plt.xlim([-0.05, 1.05])  # 设置x、y轴的上下限，以免和边缘重合，更好的观察图像的整体\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tls6Vkn0L4J-"
   },
   "outputs": [],
   "source": [
    "labels_two_class = labels\n",
    "for i in range(len(labels_two_class)):\n",
    "    if labels_two_class[i] == 0 or labels_two_class[i] == 2:\n",
    "        labels_two_class[i] = 1\n",
    "    else:\n",
    "        labels_two_class[i] = 0\n",
    "labels_two_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxhIyukrMsYW"
   },
   "outputs": [],
   "source": [
    "preds_two_class = preds\n",
    "for i in range(len(preds_two_class)):\n",
    "    if preds_two_class[i] == 0 or preds_two_class[i] == 2:\n",
    "        preds_two_class[i] = 1\n",
    "    else:\n",
    "        preds_two_class[i] = 0\n",
    "preds_two_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbiVu5KAM7a6"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels_two_class, preds_two_class)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = ['Pneumonia', 'Normal'],yticklabels = ['Pneumonia', 'Normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6TIsdg7OXj4"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "false = 0\n",
    "for i in range(len(preds_two_class)):\n",
    "    if preds_two_class[i] == labels_two_class[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        false += 1\n",
    "print(correct / (correct+false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfwspSwIbqMd"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([transforms.Resize(256),#标准化图片\n",
    "        transforms.RandomRotation(45),                  #随机旋转，-45到45度之间随机选\n",
    "        transforms.CenterCrop(224),                     #从中心开始裁剪\n",
    "        transforms.RandomHorizontalFlip(p=0.5),         #随机水平翻转 选择一个概率概率\n",
    "        transforms.RandomVerticalFlip(p=0.5),           #随机垂直翻转\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1),#参数1为亮度，参数2为对比度，参数3为饱和度，参数4为色相\n",
    "        transforms.RandomGrayscale(p=0.025),            #概率转换成灰度率，3通道就是R=G=B\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])#均值，标准差\n",
    "    ]),\n",
    "    'valid': transforms.Compose([transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YL3ZvrkUbl7f"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) for x in ['train', 'valid']}\n",
    "dataiter_train = iter(dataloaders[\"train\"])\n",
    "images_train, labels_train = next(dataiter_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlVJk4S9c_bv"
   },
   "outputs": [],
   "source": [
    "images_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rl4laXD_jHzd"
   },
   "outputs": [],
   "source": [
    "for i in range(len(labels_train)):\n",
    "    if labels_train[i] == 0 or labels_train[i] == 2:\n",
    "        labels_train[i] = 1\n",
    "    else:\n",
    "        labels_train[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvQzmIqYdOyW"
   },
   "outputs": [],
   "source": [
    "source_x = images_train\n",
    "\n",
    "source_x = (source_x.reshape(source_x.shape[0], source_x.shape[1] * source_x.shape[2] * source_x.shape[3]))\n",
    "images_train = source_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PX1-WhIrcdOw"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(images_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbgGHwIjei15"
   },
   "outputs": [],
   "source": [
    "source_x = images\n",
    "\n",
    "source_x = (source_x.reshape(source_x.shape[0], source_x.shape[1] * source_x.shape[2] * source_x.shape[3]))\n",
    "images = source_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaADAv7beiBQ"
   },
   "outputs": [],
   "source": [
    "resu = gbc.predict(images)  #进行预测\n",
    "y_pred_gbc = gbc.predict_proba(images)[:,1]  ###这玩意就是预测概率的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BuhX8QmSlnk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "fpr, tpr, thersholds = roc_curve(labels_two_class+1, y_pred_gbc ,pos_label=2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, '-', label='ROC (area = {0:.2f})'.format(roc_auc), lw=2)\n",
    " \n",
    "plt.xlim([-0.05, 1.05])  # 设置x、y轴的上下限，以免和边缘重合，更好的观察图像的整体\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM2XLP9bwCgeGNovhQLctZj",
   "mount_file_id": "1V5Nhfjj0MOfcy-UUacFHjEfcvSZhecei",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
